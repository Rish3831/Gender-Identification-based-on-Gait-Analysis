{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daca6cd7",
   "metadata": {},
   "source": [
    "# Gender Identification based on Gait Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e298029",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498547ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "male_g_fold = r'C:\\Users\\Rishwanth Mithra\\Downloads\\GEI Casia-B\\Male_New'\n",
    "female_g_fold = r'C:\\Users\\Rishwanth Mithra\\Downloads\\GEI Casia-B\\Female_New'\n",
    "\n",
    "\n",
    "def loading_folder_images(fold, lab):\n",
    "    img_ar = []\n",
    "    g_lab = []\n",
    "    for f in os.listdir(fold):\n",
    "        path_of_image = os.path.join(fold, f)\n",
    "        images = cv2.imread(path_of_image)\n",
    "        if images is not None:\n",
    "            images = cv2.resize(images, (224, 224))  \n",
    "            img_ar.append(images)\n",
    "            g_lab.append(lab)\n",
    "    return img_ar, g_lab\n",
    "\n",
    "\n",
    "images_of_male_g, labels_of_male_g = loading_folder_images(male_g_fold, 0)\n",
    "images_of_female_g, labels_of_female_g = loading_folder_images(female_g_fold, 1)\n",
    "\n",
    "\n",
    "gender_images = np.array(images_of_male_g + images_of_female_g)\n",
    "gender_labels = np.array(labels_of_male_g + labels_of_female_g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629557a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_plots(gender_images, gender_labels, number_of_samples=6):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for p in range(number_of_samples):\n",
    "        plt.subplot(2, number_of_samples, p + 1)\n",
    "        plt.imshow(cv2.cvtColor(gender_images[p], cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Male_image' if gender_labels[p] == 0 else 'Female_image')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(2, number_of_samples, number_of_samples + p + 1)\n",
    "        plt.imshow(cv2.cvtColor(gender_images[-(p + 1)], cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Male_image' if gender_labels[-(p + 1)] == 0 else 'Female_image')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "image_plots(gender_images, gender_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c336cc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "file_contain_data = r'C:\\Users\\Rishwanth Mithra\\Downloads\\GEI Casia-B\\subjects-info-pub.txt'\n",
    "\n",
    "\n",
    "data_file = pd.read_csv(file_contain_data, sep='\\t')\n",
    "\n",
    "\n",
    "print(data_file.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc45d604",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=data_file, x='Gender')\n",
    "plt.title('Distribution of Gender')\n",
    "plt.xlabel('Gender Types')\n",
    "plt.ylabel('Number of Counts')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf358c83",
   "metadata": {},
   "source": [
    "# Deep Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2ddb77",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe0ed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6532e7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_size = (128, 128)\n",
    "size_of_batch = 32\n",
    "num_of_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d894341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def images_for_CNN(g_fold, gend_label):\n",
    "    array_of_images = []\n",
    "    gender_labels = []\n",
    "    for n_f in os.listdir(g_fold):\n",
    "        path_of_images = os.path.join(g_fold, n_f)\n",
    "        gen_img = cv2.imread(path_of_images)  # Load image\n",
    "        if gen_img is not None:\n",
    "            gen_img = cv2.resize(gen_img, image_size)  # Resize for consistency\n",
    "            gen_img = cv2.cvtColor(gen_img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "            gen_img = img_to_array(gen_img)\n",
    "            array_of_images.append(gen_img)\n",
    "            gender_labels.append(gend_label)\n",
    "    return array_of_images, gender_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fd4bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnn_m_images, cnn_m_labels = images_for_CNN(r'C:\\Users\\Rishwanth Mithra\\Downloads\\GEI Casia-B\\Male_New', 0)\n",
    "cnn_f_images, cnn_f_labels = images_for_CNN(r'C:\\Users\\Rishwanth Mithra\\Downloads\\GEI Casia-B\\Female_New', 1)\n",
    "\n",
    "\n",
    "comb_g_imgs = np.concatenate((cnn_m_images, cnn_f_images), axis=0)\n",
    "comb_g_labs = np.concatenate((cnn_m_labels, cnn_f_labels), axis=0)\n",
    "\n",
    "\n",
    "comb_g_imgs = comb_g_imgs / 255.0\n",
    "comb_g_imgs = comb_g_imgs.reshape(-1, image_size[0], image_size[1], 1)  \n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "comb_g_labs = to_categorical(comb_g_labs, num_classes=2)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(comb_g_imgs, comb_g_labs, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94855dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_augment = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "data_augment.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fab0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_early_s = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c41b718",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnn_hist = cnn_model.fit(\n",
    "    data_augment.flow(X_train, y_train, batch_size=size_of_batch),\n",
    "    epochs=num_of_epochs,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[cnn_early_s]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4436e83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnn_validate = cnn_model.predict(X_test)\n",
    "cnn_valid_predict_c = np.argmax(cnn_validate, axis=1)\n",
    "cnn_valid_true_c = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a0e7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The CNN Classification Report:\")\n",
    "print(classification_report(cnn_valid_true_c, cnn_valid_predict_c, target_names=['Male Images', 'Female Images']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a960d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnn_loss, cnn_accuracy = cnn_model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {cnn_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe62054",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnn_train_pred = cnn_model.predict(X_train)\n",
    "cnn_train_rmse = np.sqrt(mean_squared_error(y_train.argmax(axis=1), cnn_train_pred.argmax(axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4752b04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_val_pred = cnn_model.predict(X_test)\n",
    "cnn_valid_rmse = np.sqrt(mean_squared_error(y_test.argmax(axis=1), cnn_val_pred.argmax(axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5b9674",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train RMSE: {cnn_train_rmse:.4f}\")\n",
    "print(f\"Validation RMSE: {cnn_valid_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712891f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnn_t_rmse_his = np.sqrt(cnn_hist.history['loss'])\n",
    "cnn_v_rmse_his = np.sqrt(cnn_hist.history['val_loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd9c128",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cnn_t_rmse_his, label='Train RMSE')\n",
    "plt.plot(cnn_v_rmse_his, label='Validation RMSE')\n",
    "plt.xlabel('num of Epochs')\n",
    "plt.ylabel('value of RMSE')\n",
    "plt.legend()\n",
    "plt.title('The CNN RMSE Curves')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be2b619",
   "metadata": {},
   "source": [
    "## Tuning Hyperparameters for CNN (Manually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38a2945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e96245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "image_size = (128, 128)\n",
    "\n",
    "\n",
    "male_g_fold = r'C:\\Users\\Rishwanth Mithra\\Downloads\\GEI Casia-B\\Male_New'\n",
    "female_g_fold = r'C:\\Users\\Rishwanth Mithra\\Downloads\\GEI Casia-B\\Female_New'\n",
    "\n",
    "\n",
    "def images_for_CNN_hyp(g_fold, gend_label):\n",
    "    array_of_images = []\n",
    "    gender_labels = []\n",
    "    for n_f in os.listdir(g_fold):\n",
    "        path_of_images = os.path.join(g_fold, n_f)\n",
    "        gen_img = cv2.imread(path_of_images)  # Load image\n",
    "        if gen_img is not None:\n",
    "            gen_img = cv2.resize(gen_img, image_size)  # Resize for consistency\n",
    "            gen_img = cv2.cvtColor(gen_img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "            gen_img = img_to_array(gen_img)\n",
    "            array_of_images.append(gen_img)\n",
    "            gender_labels.append(gend_label)\n",
    "    return array_of_images, gender_labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cnn_m_images, cnn_m_labels = images_for_CNN_hyp(male_g_fold, 0)\n",
    "cnn_f_images, cnn_f_labels = images_for_CNN_hyp(female_g_fold, 1)\n",
    "\n",
    "\n",
    "comb_g_imgs = np.concatenate((cnn_m_images, cnn_f_images), axis=0)\n",
    "comb_g_labs = np.concatenate((cnn_m_labels, cnn_f_labels), axis=0)\n",
    "\n",
    "\n",
    "comb_g_imgs = comb_g_imgs / 255.0\n",
    "\n",
    "\n",
    "comb_g_labs = to_categorical(comb_g_labs, num_classes=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c4ed24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cnn_parameters = {\n",
    "    'filters1': [32, 64],\n",
    "    'filters2': [64, 128],\n",
    "    'filters3': [128, 256],\n",
    "    'kernel_size': [(3, 3), (5, 5)],\n",
    "    'pool_size': [(2, 2), (3, 3)],\n",
    "    'optimizer': ['adam', 'sgd'],\n",
    "    'batch_size': [16, 32],\n",
    "    'epochs': [10, 20]\n",
    "}\n",
    "\n",
    "\n",
    "results = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6acf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_hype(filters1=32, filters2=64, filters3=128, kernel_size=(3, 3), pool_size=(2, 2)):\n",
    "    cnn_model = Sequential([\n",
    "        Conv2D(filters1, kernel_size, activation='relu', input_shape=(image_size[0], image_size[1], 1)),\n",
    "        MaxPooling2D(pool_size),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Conv2D(filters2, kernel_size, activation='relu'),\n",
    "        MaxPooling2D(pool_size),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Conv2D(filters3, kernel_size, activation='relu'),\n",
    "        MaxPooling2D(pool_size),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    cnn_early_s = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    \n",
    "    cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bd958d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "cnn_k_fold = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3086671",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in cnn_parameters['filters1']:\n",
    "    for j in cnn_parameters['filters2']:\n",
    "        for k in cnn_parameters['filters3']:\n",
    "            for ke in cnn_parameters['kernel_size']:\n",
    "                for p in cnn_parameters['pool_size']:\n",
    "                    cnn_high_accuracy = 0\n",
    "                    for train_index, val_index in cnn_k_fold.split(images):\n",
    "                        X_train, X_val = comb_g_imgs[train_index], comb_g_imgs[val_index]\n",
    "                        y_train, y_val = comb_g_labs[train_index], comb_g_labs[val_index]\n",
    "\n",
    "                        model = cnn_model_hype(i, j, k, kernel_size=ke, pool_size=p)\n",
    "                        model.fit(data_augment.flow(X_train, y_train, batch_size=size_of_batch),epochs=num_of_epochs,validation_data=(X_test, y_test),callbacks=[cnn_early_s])\n",
    "\n",
    "                        val_pred = model.predict(X_val)\n",
    "                        val_pred_classes = np.argmax(val_pred, axis=1)\n",
    "                        val_true_classes = np.argmax(y_val, axis=1)\n",
    "                        cnn_accuracy = accuracy_score(val_true_classes, val_pred_classes)\n",
    "                        if cnn_accuracy > cnn_high_accuracy:\n",
    "                            cnn_high_accuracy = cnn_accuracy\n",
    "                    cnn_configuration = f'filters1={i}, filters2={j}, filters3={k}, kernel_size={ke}, pool_size={p}'\n",
    "                    results[cnn_configuration] = cnn_high_accuracy\n",
    "                    print(f'{cnn_configuration} => Highest Accuracy of CNN: {cnn_high_accuracy:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07aab391",
   "metadata": {},
   "source": [
    "# Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83ba2fd",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3181983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorly.decomposition import parafac\n",
    "from tensorly import unfold, tensor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcec921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "radius_lbp = 3\n",
    "num_LBP_pnts = 8 * LBP_RADIUS\n",
    "\n",
    "\n",
    "size_of_image = (64,64)\n",
    "NUM_COMPONENTS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a826c074",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def images_loading_rf(fold, lab):\n",
    "    img_ar = []\n",
    "    g_lab = []\n",
    "    for f in os.listdir(fold):\n",
    "        path_of_image = os.path.join(fold, f)\n",
    "        images = cv2.imread(path_of_image,cv2.IMREAD_GRAYSCALE)\n",
    "        if images is not None:\n",
    "            images = cv2.resize(images, size_of_image)  # Resize for consistency\n",
    "            img_ar.append(images)\n",
    "            g_lab.append(lab)\n",
    "    return np.array(img_ar), np.array(g_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f630db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf_m_images, rf_m_labels = images_loading_rf(r'C:\\Users\\Rishwanth Mithra\\Downloads\\GEI Casia-B\\Male_New', 0)\n",
    "rf_f_images, rf_f_labels = images_loading_rf(r'C:\\Users\\Rishwanth Mithra\\Downloads\\GEI Casia-B\\Female_New', 1)\n",
    "\n",
    "\n",
    "comb_g_imgs = np.concatenate((rf_m_images, rf_f_images), axis=0)\n",
    "comb_g_labs = np.concatenate((rf_m_labels, rf_f_labels), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e34625",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rf_HOG_f(gend_imgs):\n",
    "    rf_HOG_feat = []\n",
    "    for i in gend_imgs:\n",
    "        hog_feats = hog(i, pixels_per_cell=(8, 8), cells_per_block=(2, 2), feature_vector=True)\n",
    "        rf_HOG_feat.append(hog_feats)\n",
    "    return np.array(rf_HOG_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c03b63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rf_LBP_f(gend_imgs):\n",
    "    rf_LBP_feat = []\n",
    "    for j in gend_imgs:\n",
    "        loc_bi_p = local_binary_pattern(j, num_LBP_pnts, radius_lbp, method='uniform')\n",
    "        histogrm, _ = np.histogram(loc_bi_p.ravel(), bins=np.arange(0, num_LBP_pnts + 3), range=(0, num_LBP_pnts + 2))\n",
    "        histogrm = histogrm.astype(\"float\")\n",
    "        histogrm /= (histogrm.sum() + 1e-6)  # Normalize the histogram\n",
    "        rf_LBP_feat.append(histogrm)\n",
    "    return np.array(rf_LBP_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d645fde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rf_PCA_f(gend_imgs, n_comp=50):\n",
    "    rf_flat_imges = [k.flatten() for k in gend_imgs]\n",
    "    rf_pca = PCA(n_components=n_comp)\n",
    "    rf_pca_feat = rf_pca.fit_transform(rf_flat_imges)\n",
    "    return rf_pca_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4ec398",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf_HOG_features = rf_HOG_f(comb_g_imgs)\n",
    "rf_LBP_features = rf_LBP_f(comb_g_imgs)\n",
    "rf_PCA_features = rf_PCA_f(comb_g_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ca7956",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf_comb_feats = np.concatenate((rf_HOG_features, rf_LBP_features, rf_PCA_features), axis=1)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(rf_comb_feats, comb_g_labs, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f907af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf_classif = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classif.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cee1f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "rf_y_predcts = rf_classif.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_y_predcts)\n",
    "print(f\"Random Forest Test Accuracy: {rf_accuracy * 100:.2f}%\")\n",
    "print(classification_report(y_test, rf_y_predcts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4d419c",
   "metadata": {},
   "source": [
    "## Tuning Hyperparameters for Random Forest using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135a18b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf_parameters = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "\n",
    "rand_forest_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "\n",
    "rf_g_search = GridSearchCV(estimator=rand_forest_model, param_grid=rf_parameters, cv=3, n_jobs=-1, verbose=2)\n",
    "rf_g_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "rf_best_parameters = rf_g_search.best_params_\n",
    "print(f\"Best parameters found: {rf_best_parameters}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1972ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rand_f_model_opt = RandomForestClassifier(**rf_best_parameters, random_state=42)\n",
    "rand_f_model_opt.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "rf_y_predctns = rand_f_model_opt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11829016",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Classification Report of Random Forest:\")\n",
    "print(classification_report(y_test, rf_y_predctns, target_names=['Male Images', 'Female Images']))\n",
    "\n",
    "rf_accuracy = accuracy_score(y_test, rf_y_predctns)\n",
    "print(f\"Test Accuracy of Random Forest: {rf_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6531afa",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3da6383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442a26bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def DT_Images_load(g_fold, gend_label, image_size = (224,224)):\n",
    "    array_of_images = []\n",
    "    gender_labels = []\n",
    "    for n_f in os.listdir(g_fold):\n",
    "        path_of_images = os.path.join(g_fold, n_f)\n",
    "        gen_img = cv2.imread(path_of_images)  # Load image\n",
    "        if gen_img is not None:\n",
    "            gen_img = cv2.cvtColor(gen_img, cv2.COLOR_BGR2RGB)  \n",
    "            gen_img = cv2.resize(gen_img, image_size)  # Resize for consistency\n",
    "            gen_img = preprocess_input(gen_img)\n",
    "            array_of_images.append(gen_img)\n",
    "            gender_labels.append(gend_label)\n",
    "    return np.array(array_of_images), np.array(gender_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c18bf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "male_images_d = r'C:\\Users\\Rishwanth Mithra\\Downloads\\GEI Casia-B\\Male_New'\n",
    "female_images_d = r'C:\\Users\\Rishwanth Mithra\\Downloads\\GEI Casia-B\\Female_New'\n",
    "dt_m_images, dt_m_labels = DT_Images_load(male_images_d, 0)\n",
    "dt_f_images, dt_f_labels = DT_Images_load(female_images_d, 1)\n",
    "\n",
    "\n",
    "comb_g_imgs = np.concatenate((dt_m_images, dt_f_images), axis=0)\n",
    "comb_g_labs = np.concatenate((dt_m_labels, dt_f_labels), axis=0)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(comb_g_imgs, comb_g_labs, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1990476",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dense_b_model = DenseNet121(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "\n",
    "X_trn_feat = dense_b_model.predict(X_train)\n",
    "X_tst_feat = dense_b_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc4105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dt_classif = DecisionTreeClassifier()\n",
    "dt_classif.fit(X_trn_feat, y_train)\n",
    "\n",
    "\n",
    "dt_y_predctns = dt_classif.predict(X_tst_feat)\n",
    "\n",
    "\n",
    "dt_accuracy = accuracy_score(y_test, dt_y_predctns)\n",
    "dt_cl_report = classification_report(y_test, dt_y_predctns, target_names=['Male images', 'Female images'])\n",
    "\n",
    "print(f'Accuracy of the Model: {dt_accuracy}')\n",
    "print(f'Classification Report of Decision Tree:\\n{dt_cl_report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a1bcba",
   "metadata": {},
   "source": [
    "## Tuning Hyperparameters for Decision Tree using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7870a6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dt_parameters = {\n",
    "    'max_depth': [5, 10, 15, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a253d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dt_g_search = GridSearchCV(estimator=dt_classif, param_grid=dt_parameters, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "\n",
    "dt_g_search.fit(X_trn_feat, y_train)\n",
    "\n",
    "\n",
    "dt_best_parameters = dt_g_search.best_params_\n",
    "print(f'Best parameters found: {dt_best_parameters}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc611a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dt_best_clf = dt_g_search.best_estimator_\n",
    "dt_y_predctns = dt_best_clf.predict(X_tst_feat)\n",
    "\n",
    "\n",
    "dt_accuracy = accuracy_score(y_test, dt_y_predctns)\n",
    "dt_cl_report = classification_report(y_test, dt_y_predctns, target_names=['Male Images', 'Female Images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adc442c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Accuracy: {dt_accuracy}')\n",
    "print(f'Classification Report:\\n{dt_cl_report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9adc878",
   "metadata": {},
   "source": [
    "## K-nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407650a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8533d214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_Images_load(g_fold, gend_label, image_size = (224,224)):\n",
    "    array_of_images = []\n",
    "    gender_labels = []\n",
    "    for n_f in os.listdir(g_fold):\n",
    "        path_of_images = os.path.join(g_fold, n_f)\n",
    "        gen_img = cv2.imread(path_of_images)  # Load image\n",
    "        if gen_img is not None:\n",
    "            gen_img = cv2.cvtColor(gen_img, cv2.COLOR_BGR2RGB)  \n",
    "            gen_img = cv2.resize(gen_img, image_size)  # Resize for consistency\n",
    "            gen_img = preprocess_input(gen_img)\n",
    "            array_of_images.append(gen_img)\n",
    "            gender_labels.append(gend_label)\n",
    "    return np.array(array_of_images), np.array(gender_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8ac297",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "male_d_images = r'C:\\Users\\Rishwanth Mithra\\Downloads\\GEI Casia-B\\Male_New'\n",
    "female_d_images = r'C:\\Users\\Rishwanth Mithra\\Downloads\\GEI Casia-B\\Female_New'\n",
    "knn_m_images, knn_m_labels = KNN_Images_load(male_d_images, 0)\n",
    "knn_f_images, knn_f_labels = KNN_Images_load(female_d_images, 1)\n",
    "\n",
    "\n",
    "comb_g_imgs = np.concatenate((male_images, female_images), axis=0)\n",
    "comb_g_labs = np.concatenate((male_labels, female_labels), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bc5269",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(comb_g_imgs, comb_g_labs, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "resnt_b_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "\n",
    "rsnt_trn_feat = resnt_b_model.predict(X_train)\n",
    "rsnt_tst_feat = resnt_b_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ec1984",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "knn_classif = KNeighborsClassifier(n_neighbors=5, weights='uniform', metric='euclidean')\n",
    "\n",
    "\n",
    "knn_classif.fit(rsnt_trn_feat, y_train)\n",
    "\n",
    "knn_y_predctns = knn_classif.predict(rsnt_tst_feat)\n",
    "\n",
    "\n",
    "knn_accuracy = accuracy_score(y_test, knn_y_predctns)\n",
    "knn_cl_report = classification_report(y_test, knn_y_predctns, target_names=['Male Images', 'Female Images'])\n",
    "\n",
    "print(f'KNN Accuracy: {knn_accuracy}')\n",
    "print(f'Classification Report of KNN:\\n{knn_cl_report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35870000",
   "metadata": {},
   "source": [
    "## Tuning Hyperparameters for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7096ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Images_flat = comb_g_imgs.reshape(comb_g_imgs.shape[0], -1)  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Images_flat, comb_g_labs, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e51a296",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_parameters = {\n",
    "    'n_neighbors': [3, 5, 7, 9], \n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b562073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_g_search = GridSearchCV(knn_clf, knn_parameters, cv=5, scoring='accuracy')\n",
    "knn_g_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a4386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters found:\", knn_g_search.best_params_)\n",
    "print(\"Best KNN accuracy:\", knn_g_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874f2ed2",
   "metadata": {},
   "source": [
    "# Thank you"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
